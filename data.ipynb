{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0a54b8",
   "metadata": {},
   "source": [
    "### GPU, 라이브러리 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4755ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecd6aa",
   "metadata": {},
   "source": [
    "### 데이터파일 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9582984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('C:/data/')\n",
    "labels = ['can', 'plastic']\n",
    "\n",
    "#파일 경로에있는 이미지 수 확인 \n",
    "for label in labels:\n",
    "    directory = os.path.join(train_dir, label)\n",
    "    print('Images of labels \\\"' + label + \"\\\":\", len(os.listdir(directory)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60075924",
   "metadata": {},
   "source": [
    "### 그림 10개씩 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea85a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,14))\n",
    "\n",
    "for i in range(2):\n",
    "    directory = os.path.join(train_dir,labels[i]) #directory 경로 설정 \n",
    "    for j in range(10):\n",
    "        path = os.path.join(directory, os.listdir(directory)[j]) # path\n",
    "        img = mpimg.imread(path)\n",
    "        \n",
    "        plt.subplot(2,10, i*10 + j +1)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        if j ==0:\n",
    "            plt.ylabel(labels[i], fontsize=20)\n",
    "        \n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]); \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 그림 크기 설정 \n",
    "# directory 설정(훈련데이터 경로까지)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3a486",
   "metadata": {},
   "source": [
    "### 이미지 사이즈 반틈으로 줄이기\n",
    "- 이름_half 로 저장됨\n",
    "- 실행 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd72ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dir = 'C:/data/'\n",
    "j = ['can_j', 'pla']\n",
    "for i in range(2):\n",
    "    files = glob.glob(train_dir + j[i] +\"/*.jpg\") # 경로 \n",
    "    for f in files:\n",
    "        img = Image.open(f)\n",
    "        img_resize = img.resize((int(img.width/2), int(img.height/2)))\n",
    "        title, ext = os.path.splitext(f)\n",
    "        name = os.path.basename(f)\n",
    "        img_resize.save('C:/data/can/'+name+\"_half\"+ext)\n",
    "        print(labels[i] + str(i) + '저장완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d21722",
   "metadata": {},
   "source": [
    "#### 바뀐 이미지 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e752326",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(directory+\"/can1_half.jpg\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),  \n",
    "    tf.keras.layers.Dense(2, activation='softmax'),\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07883926",
   "metadata": {},
   "source": [
    "### 데이터증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833da0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/data/train',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'C:/data/train',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e12aad4",
   "metadata": {},
   "source": [
    "### Call back 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.90):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156bf0a4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f12b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, epochs =15, verbose=1, validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657301a",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트할 이미지 경로\n",
    "image_path = '/content/gdrive/MyDrive/AIStudy/plastic.jpg'\n",
    "\n",
    "# 이미지 크기 조정\n",
    "target_size = (128, 128)\n",
    "img = image.load_img(image_path, target_size=target_size)\n",
    "img2 = image.load_img(image_path, target_size=target_size)\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img / 255.0  # 이미지를 0과 1 사이의 값으로 정규화\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(img)\n",
    "\n",
    "# 예측 결과 해석\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "class_labels = {0: 'can', 1: 'plastic'}  # 클래스 레이블과 인덱스 매핑\n",
    "\n",
    "# 예측 결과 해석\n",
    "predicted_class_index = np.argmax(predictions[0])\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "# 결과 표시\n",
    "print(\"예측된 클래스:\", predicted_class_label)\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Actual: {}      Pred: {}'.format(labels[1], predicted_class_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afca156",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6933c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('C:/Users/jihun/Classification_using_cnn/my_model.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d71255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트할 이미지 경로\n",
    "image_path = '/content/gdrive/MyDrive/AIStudy/can.jpg'\n",
    "\n",
    "# 이미지 크기 조정\n",
    "target_size = (128, 128)\n",
    "img = image.load_img(image_path, target_size=target_size)\n",
    "img2 = image.load_img(image_path, target_size=target_size)\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img / 255.0  # 이미지를 0과 1 사이의 값으로 정규화\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(img)\n",
    "\n",
    "# 예측 결과 해석\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "class_labels = {0: 'can', 1: 'plastic'}  # 클래스 레이블과 인덱스 매핑\n",
    "\n",
    "# 예측 결과 해석\n",
    "predicted_class_index = np.argmax(predictions[0])\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "# 결과 표시\n",
    "print(\"예측된 클래스:\", predicted_class_label)\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Actual: {}      Pred: {}'.format(labels[0], predicted_class_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf547b",
   "metadata": {},
   "source": [
    "### 성능확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46804180",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "plt.plot(epochs, train_acc, 'b*-', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b*-', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = validation_generator.__getitem__(1)\n",
    "# test_x is used to train the data\n",
    "# test_y refers to the actual answer of the testing set data\n",
    "# preds refers to the predicted class\n",
    "preds = model.predict(test_x)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.title('pred:%s / truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))\n",
    "    plt.imshow(test_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73626b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "ecg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
